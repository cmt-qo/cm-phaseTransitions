The provided code package simulates projections on sigma_x-basis of the toric code and identifies the position of a phase transition using a neural network. 

The user might choose one of the following processes:
1) (Minimal usage) Using the provided prediction data and the pre-trained network (checkpoints are saved) to evaluate the network in order to find the phase transition 
2) Using the provided training and prediction data in the folders 'train_data' and 'pred_data' to train the network and evaluate it to find the phase transition.
3) Running the full simulation including generation of training and prediction data, training of the network and evaluation.

We describe each of the processes in detail.


1) 
------------------------------- Minimal usage ---------------------------------------------------------------

The simulation is to be conducted in the root directory of this folder.

########################## Pre-requesites ###############################################################

The provided code "network.py" uses Python 3 and the TensorFlow library.
These codes are used to evaluate a pre-trained neural network.

#########################################################################################################


########################## Running the simulation #######################################################

The simulation can be run by executing 'python network.py'. The pre-trained neural network uses the 
checkpoints stored in the folder 'checkpoints' and the prediction data in the folder 'pred_data'
(in total 2000x30 prediction examples). The prediction data was generated for the field configuration
'Configuration 6' corresponding to the field strengths being equal on all spins.

Outcome of evaluating the network is a plot of the derivative D(beta), which indicates the phase 
transition via a divergence.

#########################################################################################################


---------------------------------------------------------------------------------------------------------





2)
--------------------------------- Evaluation and training of the network --------------------------------

The simulation is to be conducted in the root directory of this folder.

########################## Pre-requesites ###############################################################

The provided code "network.py" uses Python 3 and the TensorFlow library.
These codes are used to evaluate a pre-trained neural network.

#########################################################################################################


########################## Running the simulation #######################################################

In a first step, the network is trained. For this, the training data in the folder 'train_data' is used.
To train the network, the user should open the file 'network.py' and change the parameter 'training' 
from False to True. Then, executing 'python network.py' trains the network and stores the checkpoints 
in the folder 'checkpoints_new'. Outcome is a plot with the training and evaluation loss as a function
of training steps.

To evaluate the network on these checkpoints, open the file 'network.py', change the parameter 'training'
to False and change the folder from which the checkpoints are loaded to 'checkpoints_new' (line 182).
Running 'network.py' again gives the outcome of a plot of the derivative D(beta), which indicates the phase 
transition via a divergence.

#########################################################################################################





3)
------------------------ Generating the data -------------------------------------------------------------

The code to generate the data is provided in the folder 'Generate_spinconfigurations'.

Note that the provided code does not contain the steps for renaming and changing the format of 
generated data. These steps should be done by the user.

Change directory to 'Generate_spinconfigurations'.



####################### COMPILING THE CODE ###########################################################

The provided codes ending with ".cc" use the standard c++ library and no additional packages. They can
be compiled using the command "make" in the folder 'example_simulation_MonteCarlo'.
The executable "run_MC" is produced.

A c++11 compliant compiler is assumed. Parallel programming using OpenMP is used.
These codes are used to simulate projections via Monte Carlo sampling.

######################################################################################################


########################## RUNNING A SIMULATION ######################################################
The code is parallelized to run on 4 cores, taking less than a minute.

Once compiled, data can be generated by executing './run_MC'. In particular, the provided code outputs
spin-configurations as outcome of a projection onto sigma_x basis for 100 values of beta between
0 and 1. The output files are saved as 'spinconfs.txt' and 'betas.txt', where each row of the file 
contains a spin-configuration obtained by sampling from the ground state with the value of beta in the
same row in the file 'betas.txt'.

To convert these configurations into training, the simulation should be repeated
approximately 500 times, the produced data then shuffled and put together into a file 'train_data.txt'
(containing the spin-configurations) and 'train_labels_beta.txt' (containing the beta labels).
To obtain evaluation data, a random set of 50 examples should be removed from the training data and
stored in the files 'eval_data.txt' and 'eval_labels_beta.txt'. 

To convert the obtained configurations into prediction data, the simulation should be repeated about
2000 times, and the produced configurations and labels renamed into 'pdata{i}.txt' and 'plabels{i}.txt'.

The user might also choose to only produce training data and use the provided prediction data, or to only
use prediction data and use the provided training data.

Once the data is generated and renamed, training data should be moved to the folder 'train_data' and
prediction data to the folder 'pred_data'.


To train and evaluate the network, the user might follow the same steps as for 2).
The difference lies in specifying the amount of training and prediction data generated in the file
'network.py'. More concretely, the number of training examples has to be assigned to the parameter
'num_examples' and the number of prediction examples to the parameter 'num_predexamples'.


######################################################################################################


######################### Changing the field configuration ###########################################

The field configuration might be changed by modifying the code 'generate_spinconf.cc'.
In particular, to change the field configuration the user may change the parameter 'conf' to the
number of field configuration to be checked.

Likewise, prediction data can be generated for different field configurations and applied to the
network trained on one configuration by following the above steps.

######################################################################################################


######################### Changing the lattice size ##################################################

The lattice size can be changed by changing the parameter 'L' in all provided codes. If the lattice
size is changed, the network has to be trained on newly generated data as it changes the layers
of the network.

######################################################################################################

------------------------------------------------------------------------------------------------------


